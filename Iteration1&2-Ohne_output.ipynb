{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***ITERATION - 1***"
      ],
      "metadata": {
        "id": "da_3vDKgPVUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Study Project:** The Camera Trap Challenge\n",
        "### Computer Vision & Machine Learning Algorithms to Analyse Remote Sensing Camera Trap Data\n",
        "\n",
        "#### Mohamed Shamsudeen (536944)\n"
      ],
      "metadata": {
        "id": "mEpZa1brUfau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Coherent Sequence of Images**"
      ],
      "metadata": {
        "id": "YR0WN6nxtN3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import datetime"
      ],
      "metadata": {
        "id": "AzP2Ybikwo52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BADGER_DIR = 'E:\\WWU\\project\\SP\\og\\meles_meles_dachs\\dayvision'\n",
        "DEER_DIR = 'E:\\WWU\\project\\SP\\og\\dama\\dayvision'"
      ],
      "metadata": {
        "id": "Y0qJaSFFwqrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sequences(image_dir):\n",
        "    images = [image for image in os.listdir(image_dir)]\n",
        "    images.sort(key=lambda x: extract_timestamp(os.path.join(image_dir, x)))\n",
        "    sequences = []\n",
        "    current_sequence = []\n",
        "    previous_timestamp = None\n",
        "    for image in images:\n",
        "        timestamp = extract_timestamp(os.path.join(image_dir, image))\n",
        "        if previous_timestamp is None or (\n",
        "                timestamp - previous_timestamp).total_seconds() <= 600:  # Time interval <= 10 minutes\n",
        "            current_sequence.append(image)\n",
        "        else:\n",
        "            sequences.append(current_sequence)\n",
        "            current_sequence = [image]\n",
        "        previous_timestamp = timestamp\n",
        "    return sequences\n",
        "\n",
        "def extract_timestamp(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    exif_data = image.getexif()\n",
        "    # print(exif_data)\n",
        "    # Extract the date and time from the metadata\n",
        "    date_str = exif_data.get(306)  # DateTimeOriginal tag\n",
        "    if date_str:\n",
        "        timestamp = datetime.datetime.strptime(date_str, '%Y:%m:%d %H:%M:%S')\n",
        "        if timestamp:\n",
        "            return timestamp\n",
        "    return None"
      ],
      "metadata": {
        "id": "Lp-FfT1VtjD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "badger_sequences = extract_sequences(BADGER_DIR)\n",
        "deer_sequences = extract_sequences(DEER_DIR)\n",
        "\n",
        "for i in badger_sequences:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "C-AyelhUtNFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUXNQZtwEYiQ"
      },
      "source": [
        "# **Locate the Animals**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXn_-PZqTWB4"
      },
      "source": [
        "###MegaDetector model files\n",
        "\n",
        "We'll download both MegaDetector v5a and v5b.\n",
        "\n",
        "MDv5a-> designed to detect animal presence in camera trap images. It uses a convolutional neural network (CNN) to classify each image as containing an animal or not.\n",
        "\n",
        "MDv5b-> designed to classify species of animal detected in image. It uses a different CNN to identify the species based on features such as color, size, and shape."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install humanfriendly jsonpickle"
      ],
      "metadata": {
        "id": "l0DCumf4BMCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.10.1 torchvision==0.11.2"
      ],
      "metadata": {
        "id": "VeKR7N0ZBL5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5uwmpmaTZMX"
      },
      "outputs": [],
      "source": [
        "!wget -O /content/md_v5a.0.0.pt https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5a.0.0.pt\n",
        "!wget -O /content/md_v5b.0.0.pt https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5b.0.0.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmJ6lQX8S4im"
      },
      "source": [
        "### Required GIT repos Cloning\n",
        "To run MegaDetector, the latest versions of the Microsoft AI for Earth \"utilities\" and \"CameraTraps\" repositories and the YOLOv5 repository are required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qhltAaRSe1W"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/microsoft/CameraTraps\n",
        "!git clone https://github.com/microsoft/ai4eutils\n",
        "!git clone https://github.com/ultralytics/yolov5/\n",
        "!cd yolov5 && git checkout c23a441c9df7ca9b1f275e8c8719c949269160d1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pzfM5Y-iby1"
      },
      "source": [
        "### Set `PYTHONPATH` to include `CameraTraps`, `ai4eutils`, and `yolov5`\n",
        "\n",
        "Add cloned git folders to the `PYTHONPATH` environment variable so that we can import their modules from any working directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8vanlgAOlEj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "os.environ['PYTHONPATH'] += \":/content/ai4eutils\"\n",
        "os.environ['PYTHONPATH'] += \":/content/CameraTraps\"\n",
        "os.environ['PYTHONPATH'] += \":/content/yolov5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyjEgkCsOsak"
      },
      "source": [
        "## Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYsrTTR7eF0r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkugt7r3uUEr"
      },
      "source": [
        "## MegaDetector batch processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSIH-k0nfi73"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/My Drive/Colab Notebooks/dayvision'\n",
        "# Save output JSON file\n",
        "result = '/content/drive/My Drive/dayvision/results.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YZs9wT1sAgV"
      },
      "source": [
        "# Run detector batch\n",
        "If running in Colab session with a GPU accelerator, It process around five images per second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AOKfviGuTNg"
      },
      "outputs": [],
      "source": [
        "!python /content/CameraTraps/detection/run_detector_batch.py md_v5a.0.0.pt \"$data\" \"$result\" --recursive --output_filename --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tHu5WUGDpcd"
      },
      "source": [
        "## Visualize batch processing\n",
        "\n",
        "The `visualize_detector_output.py` in `visual` folder of Camera Traps repo to see the output of MegaDetector visualized on our images. It will save images annotated with results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en3TbCftkWDE"
      },
      "outputs": [],
      "source": [
        "# Render bounding boxes on our images\n",
        "visual = '/content/visual_img'\n",
        "!python /content/CameraTraps/visualization/visualize_detector_output.py \"$result\" \"$visual\" --confidence 0.2 --data \"$data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AglNEK0goyjA"
      },
      "outputs": [],
      "source": [
        "# Show the images with bounding boxes in Colab\n",
        "for visual_file in os.listdir(visual):\n",
        "  print(visual_file)\n",
        "  image = Image.open(os.path.join(visual, visual_file))\n",
        "  display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asIWzz-DXVRE"
      },
      "source": [
        "# **Classification of Animals**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm2yPnKV0Auc"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVyeQI0Rz0Dm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import splitfolders\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVrnMMvUUokF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAGxb4NFXiCj"
      },
      "outputs": [],
      "source": [
        "# dataset import\n",
        "drive.mount('/content/drive')\n",
        "data = '/content/drive/My Drive/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_3T4icGXh6-"
      },
      "outputs": [],
      "source": [
        "# counting the number of files in train folder\n",
        "path, dirs, files = next(os.walk('/content/drive/My Drive/data/Dee_badg'))\n",
        "count = len(files)\n",
        "print('Number of images: ', count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Xxl8GUDXhyZ"
      },
      "outputs": [],
      "source": [
        "# Importing both the deer and badger as a single file\n",
        "dee_badg = os.listdir('/content/drive/My Drive/data/Dee_badg')\n",
        "print(dee_badg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paOB-gFa0-P8"
      },
      "source": [
        "# Resize Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olHTJr9lXhkq"
      },
      "outputs": [],
      "source": [
        "#Image resized\n",
        "os.mkdir('/content/resize_img')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjgrso0l0oxc"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/My Drive/data/Dee_badg/'\n",
        "res = '/content/resize_img/'\n",
        "\n",
        "for i in range(299):\n",
        "  files = os.listdir(data)[i]\n",
        "  image_dir = data + files\n",
        "  img = Image.open(image_dir)\n",
        "  img = img.resize((299, 299))\n",
        "  img = img.convert('RGB')\n",
        "  newImgPath = res + files\n",
        "  img.save(newImgPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V4pqAe826XE"
      },
      "outputs": [],
      "source": [
        "img_dir = '/content/resize_img/'\n",
        "# get a list of all the file names in the directory\n",
        "file = os.listdir(img_dir)\n",
        "\n",
        "# store the labels\n",
        "labels = []\n",
        "# loop through each file name in directory\n",
        "for file_name in file:\n",
        "    # first character of file name\n",
        "    first_char = file_name[0]\n",
        "    # set label to 1 if first character is 'B', otherwise set it to 0\n",
        "    if first_char == 'B':\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "    # append the label to the list of labels\n",
        "    labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBJnqGT-26N0"
      },
      "outputs": [],
      "source": [
        "print(file[0:5])\n",
        "print(labels[0:5])\n",
        "print(len(file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7TD5ztM25zE"
      },
      "outputs": [],
      "source": [
        "val, cnt = np.unique(labels, return_counts=True)\n",
        "print(val)\n",
        "print(cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RgfhDIT6FWA"
      },
      "outputs": [],
      "source": [
        "img_dir = '/content/resize_img/'\n",
        "img_ext = ['JPG', 'jpg']  # image extensions to search\n",
        "files = []                # empty list to store file paths\n",
        "\n",
        "# loop through each extension in the list of extensions\n",
        "for ext in img_ext:\n",
        "    ext_files = glob.glob(img_dir + '*.' + ext)  # find all files in directory with given extension\n",
        "    files.extend(ext_files)                      # append the file paths to the list of files\n",
        "# list comprehension to read images and convert to numpy array\n",
        "bd_img = np.asarray([cv2.imread(file) for file in files])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Gz0gx5g6FO5"
      },
      "outputs": [],
      "source": [
        "print(bd_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSlUo5MW6FGm"
      },
      "outputs": [],
      "source": [
        "type(bd_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t17z1hA87w08"
      },
      "outputs": [],
      "source": [
        "print(bd_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2kprG0O7peD"
      },
      "outputs": [],
      "source": [
        "X = bd_img\n",
        "Y = np.asarray(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNLr2Dkd72Ws"
      },
      "source": [
        "# **Train Test - Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7m72sf97pao"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S2NJlqz7pX0"
      },
      "outputs": [],
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 239 - Training Images\n",
        "\n",
        "## 60  - Test Images"
      ],
      "metadata": {
        "id": "M0gyIS7FJOFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6khioFm8u1I"
      },
      "outputs": [],
      "source": [
        "# scaling the data\n",
        "X_train_scl = X_train/255\n",
        "\n",
        "X_test_scl = X_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyqTqd7V7pPE"
      },
      "outputs": [],
      "source": [
        "print(X_train_scl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jm_1fwq8ki7"
      },
      "source": [
        "## **Building Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dNaRrMO8fYn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kEj8RRv8fVP"
      },
      "outputs": [],
      "source": [
        "incp_model = ('https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5')\n",
        "pretrain_model = hub.KerasLayer(incp_model, input_shape=(299,299,3), trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xpE7XnM8fS4"
      },
      "outputs": [],
      "source": [
        "classes = 2\n",
        "model = tf.keras.Sequential([pretrain_model,tf.keras.layers.Dense(classes)])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts5ixSq78fQX"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kElfclrR8fNx"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_scl, Y_train, epochs=25, validation_data=(X_test_scl, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT91w-iv8fLS"
      },
      "outputs": [],
      "source": [
        "score, acc = model.evaluate(X_test_scl, Y_test)\n",
        "print('Test Loss =', score)\n",
        "print('Test Accuracy =', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfbkoNdn_nmf"
      },
      "outputs": [],
      "source": [
        "score, acc = model.evaluate(X_train_scl, Y_train)\n",
        "print('Train Loss =', score)\n",
        "print('Train Accuracy =', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gD-GfXa8fJi"
      },
      "outputs": [],
      "source": [
        "# plot the training and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# plot the training and validation accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samp_img = '/content/drive/My Drive/data/Dee_badg/B_BBIMG_1783.JPG'\n",
        "\n",
        "# Process the first image\n",
        "input = cv2.imread(samp_img)\n",
        "cv2_imshow(input)\n",
        "input_resize = cv2.resize(input, (299,299))\n",
        "input_scl = input_resize/255\n",
        "image_reshape = np.reshape(input_scl, [1,299,299,3])\n",
        "input_pred = model.predict(image_reshape)\n",
        "input_pred_label = np.argmax(input_pred)\n",
        "\n",
        "if input_pred_label == 0:\n",
        "    print('Badger Image')\n",
        "else:\n",
        "    print('Deer Image')"
      ],
      "metadata": {
        "id": "gYXyGMUeE0po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ITERATION-II***"
      ],
      "metadata": {
        "id": "peabnOxNNMN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Split Folders"
      ],
      "metadata": {
        "id": "GMFa44X-QHMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the path to the original folder containing all the images\n",
        "original_folder = 'C:/Users/ramkumar_m1768/Pictures/model'\n",
        "\n",
        "# Set the path to the output folder where the split folders will be created\n",
        "output_folder = 'C:/Users/ramkumar_m1768/Pictures/model/trainoutput'\n",
        "\n",
        "# Set the proportion of images to be used for the training, validation, and testing sets\n",
        "train_size = 0.7\n",
        "val_size = 0.2\n",
        "test_size = 0.1\n",
        "\n",
        "# Define a list of classes for which the subfolders will be created\n",
        "classes = ['deer', 'fox', 'badger','boar','hare','rabbit','sheep','red_deer','roh']\n",
        "\n",
        "# Loop through the list of classes\n",
        "for cls in classes:\n",
        "    # Get a list of all the image file names in the original folder for this class\n",
        "    class_folder = os.path.join(original_folder, cls)\n",
        "    image_files = os.listdir(class_folder)\n",
        "    # Split the image file names into training, validation, and testing sets\n",
        "    train_files, test_files = train_test_split(image_files, test_size=test_size, random_state=42)\n",
        "    train_files, val_files = train_test_split(train_files, test_size=val_size/(1-test_size), random_state=42)\n",
        "    # Create the output folders if they don't exist already\n",
        "    os.makedirs(os.path.join(output_folder, 'train_' + cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_folder, 'val_' + cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_folder, 'test_' + cls), exist_ok=True)\n",
        "    # Copy the training set images to the training folder\n",
        "    for file in train_files:\n",
        "        shutil.copy2(os.path.join(class_folder, file), os.path.join(output_folder, 'train_' + cls))\n",
        "    # Copy the validation set images to the validation folder\n",
        "    for file in val_files:\n",
        "        shutil.copy2(os.path.join(class_folder, file), os.path.join(output_folder, 'val_' + cls))\n",
        "    # Copy the testing set images to the testing folder\n",
        "    for file in test_files:\n",
        "        shutil.copy2(os.path.join(class_folder, file), os.path.join(output_folder, 'test_' + cls))"
      ],
      "metadata": {
        "id": "iazsFHQNNRnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WE USED MEGADETECTOR TO FIND BOUNDING BOX OF ANIMALS\n",
        "python detection\\run_detector_batch.py \"c:\\megadetector\\md_v5a.0.0.pt\" \"c:\\some_image_folder\" \"c:\\megadetector\\test_output.json\" --output_relative_filenames --recursive --checkpoint_frequency 10000 --quiet"
      ],
      "metadata": {
        "id": "KCo2blNkNRkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified Detected Category and Created Label"
      ],
      "metadata": {
        "id": "7doJMzJuQ92E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def add_category_to_detections(json_path, category_dict):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for image in data['images']:\n",
        "        directory_name = os.path.dirname(image['file'])\n",
        "\n",
        "        if 'detections' not in image:\n",
        "            continue\n",
        "       else:\n",
        "            for detection in image['detections']:\n",
        "                category_name = category_dict.get(directory_name)\n",
        "                if category_name is not None:\n",
        "                    detection['category'] = category_name\n",
        "\n",
        "    # save the modified JSON data to a new file\n",
        "    with open('valid.json', 'w') as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "\n",
        "category_dict = {\n",
        "    'val_deer'    : 'deer',\n",
        "    'val_badger'  : 'badger',\n",
        "    'val_roh'     : 'roh',\n",
        "    'val_boar'    : 'boar',\n",
        "    'val_fox'     : 'fox',\n",
        "   'val_hare'     : 'hare',\n",
        "    'val_rabbit'  : 'rabbit',\n",
        "    'val_red_deer': 'red_deer',\n",
        "    'val_sheep'   : 'sheep'}\n",
        "add_category_to_detections(â€˜md_valid.json', category_dict)\n",
        "add_category_to_detections('md_train.json', category_dict)"
      ],
      "metadata": {
        "id": "-0TuKkmoNRb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLO annotations from json file"
      ],
      "metadata": {
        "id": "9XA8VTV4Ra9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MEGADETECTOR GIVES CUSTOMISED JSON -- So we converted it\n",
        "import os\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "class_labels = {'badger': 0, 'deer': 1, 'roh': 2, 'boar': 3, 'fox': 4, 'hare': 5, 'rabbit': 6, 'red_deer': 7, 'sheep': 8}\n",
        "\n",
        "def create_yolo_annotations(json_path, class_labels):\n",
        "    # Open JSON file and load data\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    # Loop through each image in the JSON data\n",
        "    for image_data in data['images']:\n",
        "        # Get image filename and dimensions\n",
        "        image_filename = os.path.basename(image_data['file'])\n",
        "        image_path = os.path.join(os.getcwd(), os.path.dirname(image_data['file']), os.path.basename(image_data['file']))\n",
        "        try:\n",
        "            image_width, image_height = Image.open(image_path).size\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Skipping {image_path} as it is not found.\")\n",
        "            continue\n",
        "        # Loop through each detection in the image\n",
        "        annotations = []\n",
        "        if 'detections' in image_data:\n",
        "            for detection in image_data['detections']:\n",
        "                # Get class label and bounding box coordinates\n",
        "                class_label = detection['category']\n",
        "                bbox = detection['bbox']\n",
        "                x = bbox[0]\n",
        "                y = bbox[1]\n",
        "                w = bbox[2]\n",
        "                h = bbox[3]\n",
        "                x_centre = (x + (x+w))/2.0\n",
        "                y_centre = (y + (y+h))/2.0\n",
        "                x_centre = x_centre * img_w\n",
        "                y_centre = y_centre * img_h\n",
        "                w = w * img_w\n",
        "                h = h * img_h\n",
        "                x = x_centre / img_w\n",
        "                y = y_centre / img_h\n",
        "                w = w / img_w\n",
        "                h = h / img_h\n",
        "                annotation = f\"{class_labels[class_label]} {x} {y} {w} {h}\\n\"\n",
        "                annotations.append(annotation)\n",
        "        else:\n",
        "            print(\"No detections found in\", image_path)\n",
        "\n",
        "        # Write annotations to text file\n",
        "        txt_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
        "        txt_path = os.path.join(os.path.dirname(image_path), txt_filename)\n",
        "        with open(txt_path, 'w') as out_f:\n",
        "            out_f.write(\"\".join(annotations))"
      ],
      "metadata": {
        "id": "HxO9U1zGRRtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "ivApMkrbRowj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Y0iB27WETpRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --weights /kaggle/working/yolov5/md_v5a.0.0.pt --epochs 100 --batch-size 32  --data /kaggle/working/yolo.yaml --freeze 12"
      ],
      "metadata": {
        "id": "X0CqYDOcSZBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --name test --weights /kaggle/input/yolov5/best_v5.pt --exist-ok --conf-thres 0.1 --source /kaggle/working/testdata"
      ],
      "metadata": {
        "id": "pET6jrs2TxND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= YOLO(yolov8n.pt)\n",
        "model.train(data=data, epoch=200, batch = -1, patience = 30)"
      ],
      "metadata": {
        "id": "DpPV95NaRoY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(path)"
      ],
      "metadata": {
        "id": "1fU3gvVlTH4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "qyOI9EOrT57-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=data, epoch=200, batch = -1, patience = 30)"
      ],
      "metadata": {
        "id": "aOpsSqhST6pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.predict(source = path, show = True, save = True , conf = 0.5 )"
      ],
      "metadata": {
        "id": "gNisSf3vUC1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}